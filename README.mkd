Required tools and libraries
-----------------------------

Download and install nix from <https://nixos.org/download.html> (install nix, not nixOs)

Get the `trec-car-create` code from <https://github.com/TREMA-UNH/trec-car-create/>, follow the [instructions](https://github.com/TREMA-UNH/trec-car-create/blob/main/README.mkd) for compilation, and return back here.


Create new release directory
----------------------------

Check out this repository and create a directory to collect your release in,
```bash
lang=en
ver=1.6
git clone git@github.com:TREMA-UNH/trec-car-release.git release-v$lang$ver
cd release-v$lang$ver
```

Set up
---------

Set `$bin` to the location of whree the `trec-car-create` binaries reside. For instance,
```bash
export bin=$(pwd)/car-tools/bin
```

Optionally set the variable `$toolrepo` to the location of the trec-car-tools working directory



Make the `trec-car-create` tools available to the data-set build pipeline by calling:

```bash
./update-tools.sh 
```

Background: semantic changes in our `trec-car-create` tools are reflected in the version report by the `--tool-version` flag supported by each tool. Should the version change, necessary parts of the pipeline will be automatically re-run.


Configure
---------

Edit (or create) your language specific configuration file `config.*.nix` to adjust attributes

Here an example for english (`en`):

* `config.lang = "en"`
* `import_config = ./config.en.yaml`
* `globalConfig.version = "v2.5"`
* `globalConfig.dump_date = "20220101"`  // yyyymmdd

You separately need `config.*.yaml` which defines language-specific template resolution of Wikipedia. If you are using a language that does not have an existing `config.$lang.yaml`, please create a matching language configuration based on our examples. Please use the same language mnemonics as Wikipedia.

You can hard code your configuration choice by changing the top of the file `default.nix` as follows:

```nix
configFile ? ./config.en.nix   # change to a different file name
```

You can also switch off deduplication of similar paragraphs by setting `deduplicate ? false`. 


Run conversion
--------------

While technically you can call `nix-build` directly, we recommend you call it through the provided `run.sh` script.

The following commands support a test mode (where you will only use the first file of the Wikipedia dump) by adding the parameter `--arg dumpTest true`.

You can also change the config file (or deduplication mode) with `--arg configFile ./config.en.nix`

To limit the number of cores used by the conversion to `$n` by adding the parameter `--cores $n` 


### Create Wikipedia dump

To produce a car-style dump of Wikipedia. Necessary files will automatically be downloaded. 

```bash
./run.sh dump
```

your results will be collected in `result-dump`


### Create full data set

Create a dump with filtering, deduplication, outlines, paragraph corpus, and automatic ground truth, call

`./run.sh all`

your links to your results will be collected in  `result-all`


We recommend you first build a dump, then rerun with `all`. The dump will be automatically reused.



Save built data and clean up
-----------------------------


When data is built, it still resides inside the nix store. We recommend to archive it once done and clean the nix store.

copy data out of result directory using "-L" to dereference softlinks
```
rsync -L result-all $yourTargetDir
```

nix tracks which files can be purged from its store through softlinks. Only when the last link (created through nix) is deleted, it will remove the build products. Until then it slowly eats up all hard drive space.

Delete target directories of this (and previous failed attempts) in results/...-$date

call the garbage collector of nix

```
nix-gc
```


UNH only: Upload data to trec-car.cs.unh.edu
---------------------------------------------
rsync -a *v?.?*zip lava:trec-car/public_html/datareleases



